<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software.">
  <meta name="keywords" content="VideoCAD, CAD, Onshape, Dataset, UI Interactions, 3D Reasoning, NeurIPS 2025">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/videocad.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<!-- HERO TITLE -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1 publication-title">
        VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning
      </h1>
      <h2 class="subtitle is-4">NeurIPS 2025 Datasets and Benchmarks Track</h2>

      <div class="is-size-5 publication-authors">
        <span class="author-block"><a href="#">Brandon Man</a><sup>1*</sup>,</span>
        <span class="author-block"><a href="#">Ghadi Nehme</a><sup>1*</sup>,</span>
        <span class="author-block"><a href="#">Md Ferdous Alam</a><sup>1</sup>,</span>
        <span class="author-block"><a href="#">Faez Ahmed</a><sup>1</sup></span>
      </div>

      <div class="is-size-5 publication-authors">
        <span class="author-block"><sup>1</sup>Massachusetts Institute of Technology</span>
      </div>

      <p class="is-size-6" style="margin-top:0.3em;">*Equal contribution</p>

      <div class="column has-text-centered">
        <div class="publication-links">
          <!-- Paper -->
          <span class="link-block">
            <a href="https://arxiv.org/abs/2505.24838" class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="ai ai-arxiv"></i></span>
              <span>arXiv</span>
            </a>
          </span>

          <!-- Code -->
          <span class="link-block">
            <a href="https://github.com/BrandonMan123/VideoCAD"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="fab fa-github"></i></span>
              <span>Code</span>
            </a>
          </span>

          <!-- Dataset -->
          <span class="link-block">
            <a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/WX8PCK"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon"><i class="fas fa-database"></i></span>
              <span>Dataset</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- TEASER -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="./static/videos/videocad.gif"
           style="border-radius:10px; display:block; margin:0 auto 1.5rem auto; width:80%;">
      <h2 class="subtitle has-text-centered">
        <strong>VideoCAD</strong> — 41K+ Onshape CAD modeling videos with synchronized UI actions and target images.
      </h2>
    </div>
  </div>
</section>

<!-- ABSTRACT -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
  <strong>Computer-Aided Design (CAD)</strong> is a time-consuming and complex process, requiring <strong>precise, long-horizon user interactions</strong> with intricate 3D interfaces. While recent advances in <strong>AI-driven user interface (UI) agents</strong> show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, <strong>failing to capture the demands of professional engineering tools</strong>.
</p>
<p>
  In this work, we introduce <strong>VideoCAD</strong>, the <strong>first attempt at engineering UI interaction learning for precision tasks</strong>. Specifically, VideoCAD is a <strong>large-scale synthetic dataset</strong> consisting of over <strong>41K annotated video recordings of CAD operations</strong>, generated using an <strong>automated framework</strong> for collecting high-fidelity UI action data from human-made CAD designs.
</p>
<p>
  Compared to existing datasets, <strong>VideoCAD offers an order of magnitude higher complexity</strong> in UI interaction learning for real-world engineering tasks, with a significantly <strong>longer temporal horizon</strong> than other datasets. We demonstrate two important downstream applications of VideoCAD: <strong>(1) learning UI interactions from professional precision 3D CAD tools</strong> and <strong>(2) a visual question answering (VQA) benchmark</strong> designed to evaluate multimodal large language models’ (LLMs) <strong>spatial reasoning</strong> and <strong>video understanding</strong> abilities.
</p>
<p>
  To learn UI interactions, we propose <strong>VideoCADFormer</strong> — a <strong>state-of-the-art model</strong> that learns CAD interactions directly from video and <strong>outperforms multiple behavior cloning baselines</strong>. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of <strong>video-based UI understanding</strong>, including the need for <strong>precise action grounding</strong>, <strong>multimodal and spatial reasoning</strong>, and <strong>long-horizon dependencies</strong>.
</p>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero">
  <div class="hero-body has-text-centered">
    <div class="container">
      <img src="static/images/00058464.gif" width="270"/>
      <img src="static/images/00058391.gif" width="270"/>
      <img src="static/images/00053009.gif" width="270"/><br>
      <img src="static/images/00054448.gif" width="270"/>
      <img src="static/images/00055575.gif" width="270"/>
      <img src="static/images/00056215.gif" width="270"/>
    </div>
  </div>
</section>

<!-- COMPARISON TABLE -->
<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Comparison with Other UI Interaction Datasets</h2>
    <table class="table is-bordered is-striped is-hoverable is-fullwidth">
      <thead>
        <tr>
          <th>Dataset</th>
          <th># Samples</th>
          <th>Avg. Length</th>
          <th>3D Reasoning</th>
          <th>UI Actions</th>
          <th>Visual Context</th>
        </tr>
      </thead>
      <tbody>
          <tr><td>OSWorld</td><td>369</td><td>15*</td><td>❌</td><td>✅</td><td>--</td></tr>
          <tr><td>Mind2Web</td><td>2,350</td><td>7.3</td><td>❌</td><td>❌</td><td>1,135</td></tr>
          <tr><td>WebArena</td><td>812</td><td>--</td><td>❌</td><td>❌</td><td>--</td></tr>
          <tr><td>AgentStudio</td><td>304</td><td>30*</td><td>❌</td><td>✅</td><td>--</td></tr>
          <tr><td>GUI-WORLD</td><td>12,379</td><td>10.97</td><td>✅</td><td>✅</td><td>--</td></tr>
          <tr><td><strong>VideoCAD</strong></td><td><strong>41,005</strong></td><td><strong>186</strong></td><td><strong>✅</strong></td><td><strong>✅</strong></td><td><strong>6,740</strong></td></tr>
        </tbody>
    </table>
    <p><small><sup>*</sup> Max length when average not reported</small></p>
  </div>
</section>

<!-- PIPELINE -->
<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title is-3">Dataset Generation Pipeline</h2>
    <img src="./static/images/pipeline.png" alt="VideoCAD pipeline"
         style="max-width:100%; border-radius:8px; margin-bottom:1rem;">
    <p class="subtitle mt-3">
      VIDEOCAD dataset pipeline: human-authored CAD sequences are converted into UI instructions and executed via a rule-based bot to record videos. Quality filtering (DINOv2), keyframe extraction, and action alignment produce structured video-action pairs.
    </p>
  </div>
</section>

<!-- BIBTEX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
    man2025videocad,
    title={Video{CAD}: A Large-Scale Video Dataset for Learning {UI} Interactions and 3D Reasoning from {CAD} Software},
    author={Brandon Man and Ghadi Nehme and Md Ferdous Alam and Faez Ahmed},
    booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2025},
    url={https://arxiv.org/abs/2505.24838}
}</code></pre>
  </div>
</section>

<!-- FOOTER -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2505.24838"><i class="fas fa-file-pdf"></i></a>
      <a class="icon-link" href="https://github.com/BrandonMan123/VideoCAD"><i class="fab fa-github"></i></a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Website adapted from the <a href="https://nerfies.github.io">Nerfies</a> template.
            © 2025 MIT DeCoDE Lab.
          </p>
          <p>
            Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
